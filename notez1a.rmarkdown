# Logic Notebook

```{r}
suppressWarnings(suppressPackageStartupMessages({
  library(data.table)
  library(tidyverse)
  library(tidymodels)
  library(naniar)
  library(readxl)
  library(janitor)
  library(rmarkdown)
  library(knitr)
  library(kableExtra)
  library(modelsummary)
  library(DoubleML)
  library(mlr3)
  library(broom)
  library(ranger)
  library(sandwich)
  library(lmtest)
  library(mlr3learners)
  library(readr)
  library(MatchIt)
  library(ggplot2)
  library(dplyr)
  library(summarytools)
  library(DataExplorer)
  library(mlr3learners)
  library(mlr3measures)
  library(mlr3resampling)
}))
set.seed(5824769)
options(warn = -1)
options(device.ask.default = FALSE)
data010a <- rnorm(1000000)
hist(
  data010a,
  labels = TRUE,
  col = "grey",
  breaks = 100,
  main = "Histogram of Random Data",
  xlab = "Value",
  ylab = "Frequency"
)
rdx = rnorm(1000)
rdy = as.numeric(rdx > 0)
rdix = sample(1:1000, 100)
rdy[rdix] = 1 - rdy[rdix]
rdf = data.frame(rdx, rdy)
plot(rdf$rdx, rdf$rdy)
m <- glm(rdy ~ rdx, data = rdf, family = binomial())
xs <- seq(min(rdf$rdx), max(rdf$rdx), length.out = 300)
lines(
  xs,
  predict(m, newdata = data.frame(rdx = xs), type = "response"),
  lwd = 2
)
load("correctional_stats_report_environment1b.RData")

dataframe_original <- df
cols_to_rename <- setdiff(names(dataframe_original), "unique_individual_id")
num_to_letters <- function(n) {
  sapply(n, function(i) {
    out <- ""
    while (i > 0) {
      i <- i - 1
      out <- paste0(letters[(i %% 26) + 1], out)
      i <- i %/% 26
    }
    out
  })
}
new_names <- paste0("x1", num_to_letters(seq_along(cols_to_rename)))
names(dataframe_original)[match(
  cols_to_rename,
  names(dataframe_original)
)] <- new_names
knitr::kable(
  head(
    dataframe_original[, setdiff(
      names(dataframe_original),
      "unique_individual_id"
    )],
    10
  ),
  booktabs = TRUE,
  longtable = TRUE,
  caption = "Ontario Restrictive Confinement Dataframe (2023-2025)"
)

region_names <- c("Central", "Eastern", "Northern", "Toronto", "Western")
age_levels <- c("18 to 24", "25 to 49", "50+")
sex_levels <- c("Male", "Female")
years <- 2023:2025
dataframe_original1b <- copy(dataframe_original)
df_rc <- as.data.table(df)
df_rc[, end_fiscal_year := as.integer(end_fiscal_year)]
df_rc[, age_category := factor(age_category, levels = age_levels)]
df_rc[, gender := factor(gender, levels = sex_levels)]
df_rc[,
  region_at_time_of_placement := factor(
    region_at_time_of_placement,
    levels = region_names
  )
]
get_region_by_age <- function(D, yr, sex = NULL) {
  tmp <- D[
    end_fiscal_year == yr &
      !is.na(age_category) &
      !is.na(region_at_time_of_placement)
  ]
  if (!is.null(sex)) {
    tmp <- tmp[gender == sex]
  }
  tab <- tmp[,
    .(n = uniqueN(unique_individual_id)),
    by = .(age_category, region_at_time_of_placement)
  ]
  grid <- CJ(
    age_category = age_levels,
    region_at_time_of_placement = region_names,
    unique = TRUE
  )
  tab <- merge(
    grid,
    tab,
    by = c("age_category", "region_at_time_of_placement"),
    all.x = TRUE
  )
  tab[is.na(n), n := 0L]
  wide <- dcast(
    tab,
    age_category ~ region_at_time_of_placement,
    value.var = "n"
  )
  S <- as.matrix(wide[, -1])
  rownames(S) <- wide$age_category
  den <- rowSums(S)
  P <- sweep(S, 1, den, "/")
  P[den == 0, ] <- NA_real_
  list(S = S, P = P)
}
P_year <- list()
S_year <- list()
for (yr in years) {
  out_all <- get_region_by_age(df_rc, yr)
  P <- out_all$P
  S_year[[as.character(yr)]] <- out_all$S
  P_year[[as.character(yr)]] <- P
  cols <- seq_len(ncol(P))
  matplot(
    P,
    type = "l",
    lwd = 2,
    lty = 1,
    col = cols,
    xaxt = "n",
    xlab = "Age Group",
    ylab = "Proportion",
    main = paste0(yr, " Region at Time of Placement by Age Group")
  )
  axis(1, at = seq_len(nrow(P)), labels = rownames(P))
  legend(
    "topright",
    legend = colnames(P),
    col = cols,
    lty = 1,
    lwd = 2,
    bty = "n"
  )
  par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))
  for (sex in c("Male", "Female")) {
    out_sex <- get_region_by_age(df_rc, yr, sex = sex)
    Psex <- out_sex$P
    cols <- seq_len(ncol(Psex))
    matplot(
      Psex,
      type = "l",
      lwd = 2,
      lty = 1,
      col = cols,
      xaxt = "n",
      xlab = "Age Group",
      ylab = "Proportion",
      main = paste0(yr, " RTP (", sex, ")")
    )
    axis(1, at = seq_len(nrow(Psex)), labels = rownames(Psex))
    legend(
      "topright",
      legend = colnames(Psex),
      col = cols,
      lty = 1,
      lwd = 2,
      bty = "n"
    )
  }
  par(mfrow = c(1, 1))
}


ac1b <- df |>
  mutate(
    ac1a = factor(
      dplyr::recode(
        as.character(age_category),
        "18 to 24" = "1",
        "25 to 49" = "2",
        "50+" = "3"
      ),
      levels = c("1", "2", "3"),
      ordered = TRUE
    )
  ) |>
  group_by(ac1a) |>
  summarise(
    f = dplyr::n(),
    n = dplyr::n_distinct(unique_individual_id),
    .groups = "drop"
  ) |>
  arrange(ac1a) |>
  mutate(
    p = round(n / sum(n), 2),
    pct = round(100 * n / sum(n), 2),
    rate = round(10000 * n / sum(n), 2)
  )
vars <- c(
  "gender",
  "age_category",
  "region_at_time_of_placement",
  "region_most_recent_placement",
  "mental_health_alert",
  "suicide_watch_alert",
  "suicide_risk_alert"
)
df.counts <- df |>
  group_by(region_at_time_of_placement) |>
  summarise(
    f = n(),
    count = n_distinct(unique_individual_id),
    .groups = "drop"
  ) |>
  mutate(p = count / sum(count), pct = p * 100, rate = p * 10000)
df.counts_ac_year <- df |>
  pivot_longer(all_of(vars), names_to = "variable", values_to = "level") |>
  group_by(end_fiscal_year, variable, level) |>
  summarise(
    f = n(),
    count = n_distinct(unique_individual_id),
    .groups = "drop"
  ) |>
  group_by(end_fiscal_year, variable) |>
  mutate(p = count / sum(count), pct = 100 * p, rate = 10000 * p) |>
  ungroup()
df.counts_year <- df |>
  group_by(end_fiscal_year, region_at_time_of_placement) |>
  summarise(
    f = n(),
    count = n_distinct(unique_individual_id),
    .groups = "drop"
  ) |>
  group_by(end_fiscal_year) |>
  mutate(p = count / sum(count), pct = 100 * p, rate = 10000 * p) |>
  ungroup()
df.person_freq_year <- df |>
  group_by(
    end_fiscal_year,
    region_at_time_of_placement,
    unique_individual_id
  ) |>
  summarise(freq = n(), .groups = "drop")
ecdf_age <- ac1b |>
  arrange(ac1a) |>
  mutate(ecdf = cumsum(p))
events_per_person <- df |>
  count(unique_individual_id, name = "n_events") |>
  pull(n_events)
total_people <- df |>
  summarise(N = n_distinct(unique_individual_id)) |>
  pull(N)
df_overall <- df |>
  select(unique_individual_id, all_of(vars)) |>
  pivot_longer(all_of(vars), names_to = "variable", values_to = "level") |>
  group_by(variable, level) |>
  summarise(
    f = n(),
    count = n_distinct(unique_individual_id),
    .groups = "drop"
  ) |>
  mutate(
    p = count / total_people,
    pct = 100 * p,
    rate = 10000 * p
  )

knitr::kable(
  ecdf_age,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`ecdf_age`)'
)
knitr::kable(
  df.counts,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`df.counts`).'
)
knitr::kable(
  df.counts_year,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`df.counts_year`)'
)
knitr::kable(
  df_overall,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`df_overall`)'
)
knitr::kable(
  df.counts_ac_year,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`df.counts_ac_year`)'
)

library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
library(dplyr)
library(parallel)
lgr::get_logger("mlr3")$set_threshold("warn")
# "regr.lm" instead of "regr.ranger" utilized (disclaimer)
# "classif.log_reg", predict_type = "prob" instead of classif.ranger
# cores <- max(1L, parallel::detectCores() - 1L)
# yn_cols <- c("mental_health_alert", "suicide_risk_alert", "suicide_watch_alert")
# dfn <- dfn %>%
#   mutate(across(
#     all_of(yn_cols),
#     ~ factor(dplyr::if_else(.x == "Yes", 1L, 0L), levels = c(0, 1))
#   ))
# dt <- as.data.table(dfn)
# dt[, number_of_placements := as.integer(number_of_placements)]
# dt <- dt[!is.na(number_of_placements) & number_of_placements > 0L]
# N_expanded <- sum(dt$number_of_placements)
# message("Expanded N = ", format(N_expanded, big.mark = ","))
# dt <- dt[rep.int(seq_len(.N), number_of_placements)]
# dt[, Y := as.integer(suicide_risk_alert) - 1L]
# dt[, D := as.integer(mental_health_alert) - 1L]
# stopifnot(identical(sort(unique(dt$D)), c(0L, 1L)))
# dt[, cluster_id := as.factor(unique_individual_id)]
# ml_g <- lrn("regr.lm")
# ml_m <- lrn("classif.log_reg", predict_type = "prob")
# fit_irm_ate_atte <- function(dsub, x_cols, tag) {
#   dml_data <- DoubleMLClusterData$new(
#     data = dsub,
#     y_col = "Y",
#     d_cols = "D",
#     x_cols = x_cols,
#     cluster_cols = "cluster_id"
#   )
#   set.seed(1111111111)
#   obj_ate <- DoubleMLIRM$new(
#     dml_data,
#     ml_g = ml_g,
#     ml_m = ml_m,
#     n_folds = 3,
#     n_rep = 1,
#     score = "ATE"
#   )
#   obj_ate$fit()
#   set.seed(1111111111)
#   obj_atte <- DoubleMLIRM$new(
#     dml_data,
#     ml_g = ml_g,
#     ml_m = ml_m,
#     n_folds = 3,
#     n_rep = 1,
#     score = "ATTE"
#   )
#   obj_atte$fit()
#   mk <- function(obj, estimand) {
#     ci <- obj$confint(level = 0.95)
#     data.table(
#       group = tag,
#       estimand = estimand,
#       effect = as.numeric(obj$coef),
#       se = as.numeric(obj$se),
#       t_value = as.numeric(obj$t_stat),
#       p_value = as.numeric(obj$pval),
#       ci_low = as.numeric(ci[1, 1]),
#       ci_high = as.numeric(ci[1, 2])
#     )
#   }
#   rbind(mk(obj_ate, "ATE"), mk(obj_atte, "ATTE"))
# }
# x_cols_pool <- c(
#   "gender",
#   "age_category",
#   "region_at_time_of_placement",
#   "region_most_recent_placement",
#   "end_fiscal_year"
# )
# dt[, (x_cols_pool) := lapply(.SD, as.factor), .SDcols = x_cols_pool]
# keep_pool <- complete.cases(dt[,
#   c("Y", "D", "cluster_id", x_cols_pool),
#   with = FALSE
# ])
# dsub_pool <- dt[keep_pool, c("Y", "D", "cluster_id", x_cols_pool), with = FALSE]
# res_pool <- fit_irm_ate_atte(dsub_pool, x_cols_pool, tag = "Pooled 2023-25")
# years <- sort(unique(dt$end_fiscal_year))
# x_cols_year <- c(
#   "gender",
#   "age_category",
#   "region_at_time_of_placement",
#   "region_most_recent_placement"
# )
# res_by_year <- rbindlist(lapply(years, function(yy) {
#   sub <- dt[end_fiscal_year == yy]
#   sub[, (x_cols_year) := lapply(.SD, as.factor), .SDcols = x_cols_year]
#   keep_y <- complete.cases(sub[,
#     c("Y", "D", "cluster_id", x_cols_year),
#     with = FALSE
#   ])
#   dsub_y <- sub[keep_y, c("Y", "D", "cluster_id", x_cols_year), with = FALSE]
#   fit_irm_ate_atte(dsub_y, x_cols_year, tag = as.character(yy))
# }))

setHook(packageEvent("graphics", "onLoad"), function(...) par(ask = FALSE))
setnames(
  dataframe_original,
  old = c(
    "x1a",
    "unique_individual_id",
    "x1b",
    "x1c",
    "x1d",
    "x1f",
    "x1g",
    "x1h",
    "x1i"
  ),
  new = c("year", "id", "regA", "regB", "sex", "binA", "binB", "binC", "np")
)

dt1b <- as.data.table(dataframe_original)
placement_dist <- dt1b[,
  .(
    total_placements = sum(np),
    unique_status_rows = .N
  ),
  by = .(id, year)
]

summary_report <- placement_dist[,
  .(
    total_unique_people = .N,
    avg_placements_per_person = mean(total_placements),
    median_placements = median(total_placements),
    max_placements = max(total_placements),
    avg_status_changes = mean(unique_status_rows),
    max_status_changes = max(unique_status_rows)
  ),
  by = year
][order(year)]

# Summary of Placement Distribution by Year
knitr::kable(
  summary_report,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`summary_report`)'
)
# Frequency of Status Combinations per Person
as.data.frame(table(placement_dist$unique_status_rows))
placement_rows <- as.data.frame(table(placement_dist$unique_status_rows))
knitr::kable(
  placement_rows,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`placement_rows`)'
)
top_rows <- placement_dist[order(-unique_status_rows)][1:10]
knitr::kable(
  top_rows,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`top_rows`)'
)

row_counts_summary <- placement_dist[,
  .(count_of_people = .N),
  by = unique_status_rows
][order(unique_status_rows)]
# how many people have 1, 2,...n rows ?:!
knitr::kable(
  row_counts_summary,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`row_counts_summary`)'
)

setnames(dt1b, "x1e", "age")
bin_cols <- c("binA", "binB", "binC")
dt1b[,
  (bin_cols) := lapply(.SD, function(x) ifelse(x == "Yes", 1L, 0L)),
  .SDcols = bin_cols
]
dt1b[age == "18 to 24", `:=`(age_num = 21, age_order = 1L)]
dt1b[age == "25 to 49", `:=`(age_num = 42, age_order = 2L)]
dt1b[age == "50+", `:=`(age_num = 57.5, age_order = 3L)]
dt1b[,
  age_factor := factor(
    age,
    levels = c("A", "B", "C"),
    ordered = TRUE
  )
]
cat_cols <- c("regA", "regB", "sex")
dt1b[, (cat_cols) := lapply(.SD, as.factor), .SDcols = cat_cols]

dt1b[, a1 := as.integer(binA == 1 & binB == 0 & binC == 0)] # 1,0,0
dt1b[, a2 := as.integer(binA == 0 & binB == 1 & binC == 0)] # 0,1,0
dt1b[, a3 := as.integer(binA == 0 & binB == 0 & binC == 1)] # 0,0,1
dt1b[, a4 := as.integer(binA == 1 & binB == 1 & binC == 0)] # 1,1,0
dt1b[, a5 := as.integer(binA == 0 & binB == 1 & binC == 1)] # 0,1,1
dt1b[, a6 := as.integer(binA == 1 & binB == 0 & binC == 1)] # 1,0,1
dt1b[, a7 := as.integer(binA == 1 & binB == 1 & binC == 1)] # 1,1,1
dt1b[, a8 := as.integer(binA == 0 & binB == 0 & binC == 0)] # 0,0,0

dt_unbiased <- dt1b[,
  .(
    a1 = sum(a1 * np),
    a2 = sum(a2 * np),
    a3 = sum(a3 * np),
    a4 = sum(a4 * np),
    a5 = sum(a5 * np),
    a6 = sum(a6 * np),
    a7 = sum(a7 * np),
    a8 = sum(a8 * np),
    Y = sum(binB * np) / sum(np),
    D = sum(binA * np) / sum(np),
    total_np = sum(np),
    age_val = first(age_num),
    sex = first(sex),
    regA = first(regA)
  ),
  by = .(id, year)
]

state_cols <- paste0("a", 1:8)
dt_unbiased[, combo_count := rowSums(.SD > 0), .SDcols = state_cols]
dt_8 <- dt_unbiased[combo_count == 8]
dt_7 <- dt_unbiased[combo_count == 7]
dt_6 <- dt_unbiased[combo_count == 6]
dt_5 <- dt_unbiased[combo_count == 5]
dt_4 <- dt_unbiased[combo_count == 4]
dt_3 <- dt_unbiased[combo_count == 3]
dt_2 <- dt_unbiased[combo_count == 2]
dt_1 <- dt_unbiased[combo_count == 1]
dt_2plus <- dt_unbiased[combo_count >= 2]

subset_summary <- dt_unbiased[, .(n_persons = .N), by = combo_count][order(
  -combo_count
)]
knitr::kable(
  subset_summary,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`subset_summary`)'
)
print(paste(
  "Number of rows with NA combo_count:",
  sum(is.na(dt_unbiased$combo_count))
))

alert_stats <- summary(dt_unbiased[, .(a1, a2, a3, a4, a5, a6, a7, a8)])
knitr::kable(
  alert_stats,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`alert_stats`)'
)

dt_unbiased[,
  combo_count_robust := rowSums(.SD > 0, na.rm = TRUE),
  .SDcols = state_cols
]

alert_stats1a <- as.data.frame(table(dt_unbiased$combo_count_robust)) 

# Then pass it to kable
knitr::kable(
  alert_stats1a,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`alert_stats1a`)'
)
top_ids <- placement_dist[unique_status_rows >= 7, id]
complex_moves <- dt_unbiased[id %in% top_ids]
print(complex_moves[, .(id, combo_count, total_np, a1, a2, a4, a5, a7, a8)])
knitr::kable(
  complex_moves[, .(id, combo_count, total_np, a1, a2, a4, a5, a7, a8)],
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`complex_moves`)'
)

region_profile <- dcast(
  dt1b[id %in% top_ids],
  id + year ~ regA,
  value.var = "np",
  fun.aggregate = sum
)

complex_subset <- merge(
  dt_unbiased[
    id %in% top_ids,
    .(id, year, combo_count, total_np, a1, a2, a4, a5, a7, a8)
  ],
  region_profile,
  by = c("id", "year")
)
knitr::kable(
  complex_subset,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`complex_subset`)'
)

dt_complex_raw <- dt1b[id %in% top_ids]
regA_counts <- dcast(
  dt_complex_raw,
  id + year ~ regA,
  value.var = "np",
  fun.aggregate = sum
)
setnames(
  regA_counts,
  old = setdiff(names(regA_counts), c("id", "year")),
  new = paste0(setdiff(names(regA_counts), c("id", "year")), "_A")
)

regB_counts <- dcast(
  dt_complex_raw,
  id + year ~ regB,
  value.var = "np",
  fun.aggregate = sum
)
setnames(
  regB_counts,
  old = setdiff(names(regB_counts), c("id", "year")),
  new = paste0(setdiff(names(regB_counts), c("id", "year")), "_B")
)

complex_subset <- merge(
  dt_unbiased[
    id %in% top_ids,
    .(id, year, combo_count, total_np, a1, a2, a4, a5, a7, a8)
  ],
  regA_counts,
  by = c("id", "year"),
  all.x = TRUE
)
complex_subset <- merge(
  complex_subset,
  regB_counts,
  by = c("id", "year"),
  all.x = TRUE
)

complex_subset[is.na(complex_subset)] <- as.double(0)

knitr::kable(
  complex_subset,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`complex_subset`)'
)

all_regions <- c("Toronto", "Central", "Eastern", "Western", "Northern")
dt_complex_raw <- dt1b[id %in% top_ids]
dt_complex_raw[, regA := factor(regA, levels = all_regions)]
dt_complex_raw[, regB := factor(regB, levels = all_regions)]

regA_counts <- dcast(
  dt_complex_raw,
  id + year ~ regA,
  value.var = "np",
  fun.aggregate = sum,
  drop = FALSE
)

setnames(regA_counts, old = all_regions, new = paste0(all_regions, "_A"))

regB_counts <- dcast(
  dt_complex_raw,
  id + year ~ regB,
  value.var = "np",
  fun.aggregate = sum,
  drop = FALSE
)

setnames(regB_counts, old = all_regions, new = paste0(all_regions, "_B"))

complex_subset <- dt_unbiased[
  id %in% top_ids,
  .(id, year, combo_count, total_np, a1, a2, a4, a5, a7, a8)
]

complex_subset <- merge(
  complex_subset,
  regA_counts,
  by = c("id", "year"),
  all.x = TRUE
)
complex_subset <- merge(
  complex_subset,
  regB_counts,
  by = c("id", "year"),
  all.x = TRUE
)

cols_to_fix <- c(paste0(all_regions, "_A"), paste0(all_regions, "_B"))
complex_subset[,
  (cols_to_fix) := lapply(.SD, function(x) ifelse(is.na(x), 0, x)),
  .SDcols = cols_to_fix
]

# Complex Cases (10 Regional Columns + Possible Alert Status Combinations)
knitr::kable(
  complex_subset,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`complex_subset`)'
)

dt_moves_corrected <- dt1b[
  order(id, year),
  .(
    id,
    year,
    internal_move = as.integer(regA != regB),
    external_move = as.integer(regA != shift(regA, type = "lag"))
  ),
  by = .(id, year)
]
regional_volatility <- dt_moves_corrected[,
  .(
    total_regional_changes = sum(
      internal_move == 1 | (external_move == 1 & !is.na(external_move))
    )
  ),
  by = .(id, year)
]
dt_unbiased <- merge(
  dt_unbiased,
  regional_volatility,
  by = c("id", "year"),
  all.x = TRUE
)
move_summary <- dt_unbiased[,
  .(n_persons = .N),
  by = total_regional_changes
][order(total_regional_changes)]
print(move_summary)
region_counts_per_id <- dt1b[,
  .(
    unique_regions = list(unique(c(regA, regB)))
  ),
  by = .(id, year)
]
region_counts_per_id[, n_regions := sapply(unique_regions, length)]
multi_region_ids <- region_counts_per_id[n_regions > 1]
total_multi_region_persons <- nrow(multi_region_ids)
total_unique_persons <- nrow(region_counts_per_id)

print(paste("Total Unique Person-IDs in dataset:", total_unique_persons))
print(paste("Number of Person-IDs with >1 region:", total_multi_region_persons))
print(paste(
  "Percentage of population moving regions:",
  round((total_multi_region_persons / total_unique_persons) * 100, 2),
  "%"
))

reg_count_id <- table(region_counts_per_id$n_regions)
knitr::kable(
  reg_count_id,
  booktabs = TRUE,
  longtable = TRUE,
  caption = '(`reg_count_id`)'
)

dt1b[,
  status_combo := case_when(
    binA == 1 & binB == 0 & binC == 0 ~ "a1",
    binA == 0 & binB == 1 & binC == 0 ~ "a2",
    binA == 0 & binB == 0 & binC == 1 ~ "a3",
    binA == 1 & binB == 1 & binC == 0 ~ "a4",
    binA == 0 & binB == 1 & binC == 1 ~ "a5",
    binA == 1 & binB == 0 & binC == 1 ~ "a6",
    binA == 1 & binB == 1 & binC == 1 ~ "a7",
    binA == 0 & binB == 0 & binC == 0 ~ "a8"
  )
]

dt1b[, reg_status_key := paste0(regA, "_", status_combo)]
dt_40state <- dcast(
  dt1b,
  id + year + sex + age_num + age_order ~ reg_status_key,
  value.var = "np",
  fun.aggregate = sum,
  fill = 0
)

print(paste("Number of columns in the new state-space:", ncol(dt_40state)))
head(dt_40state)

state_totals <- colSums(dt_40state[, .SD, .SDcols = patterns("_a[1-8]")])

state_summary <- data.table(
  state = names(state_totals),
  total_placements = state_totals
)[order(-total_placements)]

print("Top Ten Empirical Region-Status combinations:")
print(head(state_summary, 10))

id_counts <- dt_40state[,
  lapply(.SD, function(x) sum(x > 0)),
  .SDcols = patterns("_a[1-8]")
]

id_counts_t <- data.table(
  state = names(id_counts),
  count_of_people = as.numeric(id_counts)
)[order(-count_of_people)]

print("Number of unique individuals who entered each state:")
print(id_counts_t)

dt_40state[, states_visited := rowSums(.SD > 0), .SDcols = patterns("_a[1-8]")]

complexity_dist <- dt_40state[, .(n_people = .N), by = states_visited][order(
  states_visited
)]

print("How many unique Region-Status states did people visit?")
print(complexity_dist)

dt1b[,
  status_combo := case_when(
    binA == 1 & binB == 0 & binC == 0 ~ "a1",
    binA == 0 & binB == 1 & binC == 0 ~ "a2",
    binA == 0 & binB == 0 & binC == 1 ~ "a3",
    binA == 1 & binB == 1 & binC == 0 ~ "a4",
    binA == 0 & binB == 1 & binC == 1 ~ "a5",
    binA == 1 & binB == 0 & binC == 1 ~ "a6",
    binA == 1 & binB == 1 & binC == 1 ~ "a7",
    binA == 0 & binB == 0 & binC == 0 ~ "a8"
  )
]

dt1b[, reg_status_key := paste0(regA, "_", status_combo)]
dt_40state_yearly <- dcast(
  dt1b,
  id + year + sex + age_num ~ reg_status_key,
  value.var = "np",
  fun.aggregate = sum,
  fill = 0
)

yearly_stats <- dt_40state_yearly[,
  .(
    unique_ids = uniqueN(id),
    total_placements = sum(.SD, na.rm = TRUE)
  ),
  by = year,
  .SDcols = patterns("_a[1-8]")
]

print(yearly_stats)

split_summary <- dt_40state_yearly[,
  lapply(.SD, sum),
  by = year,
  .SDcols = patterns("_a[1-8]")
]

print("First few rows of 2023 data:")
head(dt_40state_yearly[year == 2023])
dt_40state_yearly[,
  combinations_this_year := rowSums(.SD > 0),
  .SDcols = patterns("_a[1-8]")
]
table(dt_40state_yearly$year, dt_40state_yearly$combinations_this_year)

id_counts_yearly <- dt_40state_yearly[,
  lapply(.SD, function(x) sum(x > 0)),
  by = year,
  .SDcols = patterns("_a[1-8]")
]

id_counts_long <- melt(
  id_counts_yearly,
  id.vars = "year",
  variable.name = "state",
  value.name = "person_count"
)

id_counts_long <- id_counts_long[order(year, -person_count)]
print("Top 5 most frequent Region-Status states per year:")
print(id_counts_long[, head(.SD, 5), by = year])
empty_states <- id_counts_long[,
  .(total_across_years = sum(person_count)),
  by = state
][total_across_years == 0]

print("States with zero occupancy (these won't help the DoubleML):")
print(empty_states$state)
reg_summary <- dt1b[,
  .(
    reg_count = uniqueN(c(regA, regB)),
    regC = paste(sort(unique(c(regA, regB))), collapse = " + ")
  ),
  by = .(id, year)
]

status_summary <- dcast(
  dt1b,
  id + year ~ status_combo,
  value.var = "np",
  fun.aggregate = sum,
  fill = 0
)

dt_final_complex <- merge(status_summary, reg_summary, by = c("id", "year"))

demo_info <- dt1b[,
  .(
    sex = first(sex),
    age_num = first(age_num)
  ),
  by = .(id, year)
]

dt_final_complex <- merge(dt_final_complex, demo_info, by = c("id", "year"))

print(head(dt_final_complex))

regC_stats <- dt_final_complex[, .(n_persons = .N), by = regC][order(
  -n_persons
)]
print(regC_stats)

regC_yearly_counts <- dt_final_complex[, .(n = .N), by = .(regC, year)]

regC_stats_wide <- dcast(
  regC_yearly_counts,
  regC ~ year,
  value.var = "n",
  fill = 0
)

year_cols <- setdiff(names(regC_stats_wide), "regC")
new_t_names <- paste0("t", seq_along(year_cols))
setnames(regC_stats_wide, old = year_cols, new = new_t_names)

regC_stats_wide[, n_persons := rowSums(.SD), .SDcols = new_t_names]

setcolorder(regC_stats_wide, c("regC", "n_persons", new_t_names))
regC_stats_wide <- regC_stats_wide[order(-n_persons)]

print(regC_stats_wide)

demog_counts <- dt_final_complex[, .(n = .N), by = .(regC, year, sex)]

demog_wide <- dcast(demog_counts, regC ~ year + sex, value.var = "n", fill = 0)

unique_years <- sort(unique(demog_counts$year))

for (i in seq_along(unique_years)) {
  year_val <- unique_years[i]
  suffix <- letters[i]
  setnames(
    demog_wide,
    old = paste0(year_val, "_Male"),
    new = paste0("g1", suffix),
    skip_absent = TRUE
  )
  setnames(
    demog_wide,
    old = paste0(year_val, "_Female"),
    new = paste0("g2", suffix),
    skip_absent = TRUE
  )
}

demog_wide[, t1 := g1a + g2a]
demog_wide[, t2 := g1b + g2b]
demog_wide[, t3 := g1c + g2c]

demog_wide[, n_persons := t1 + t2 + t3]

setcolorder(
  demog_wide,
  c(
    "regC",
    "n_persons",
    "t1",
    "t2",
    "t3",
    "g1a",
    "g1b",
    "g1c",
    "g2a",
    "g2b",
    "g2c"
  )
)
regC_demog_stats <- demog_wide[order(-n_persons)]

print(regC_demog_stats)

knitr::kable(res_pool, digits = 4, caption = "Pooled IRM DoubleML (2023–2025)")
knitr::kable(
  res_by_year,
  digits = 4,
  caption = "Yearly IRM DoubleML (2023/2024/2025)"
)
knitr::kable(
  res_pool,
  booktabs = TRUE,
  longtable = TRUE,
  digits = 4,
  caption = "Pooled IRM DoubleML (2023–2025)"
)
knitr::kable(
  res_by_year,
  booktabs = TRUE,
  longtable = TRUE,
  digits = 4,
  caption = "IRM DoubleML (2023/2024/2025)"
)

dt1c <- as.data.table(dataframe_original1b)
setnames(
  dt1c,
  old = c(
    "x1a",
    "unique_individual_id",
    "x1b",
    "x1c",
    "x1d",
    "x1e",
    "x1f",
    "x1g",
    "x1h",
    "x1i"
  ),
  new = c("year", "id", "regA", "regB", "sex", "age", "bA", "bB", "bC", "np"),
  skip_absent = TRUE
)

dt1c[, `:=`(
  bA = as.integer(bA == "Yes"),
  bB = as.integer(bB == "Yes"),
  bC = as.integer(bC == "Yes"),
  age_n = fcase(
    age == "18 to 24" , 21   ,
    age == "25 to 49" , 42   ,
    age == "50+"      , 57.5
  )
)]

dt1c[,
  combo := fcase(
    bA == 1 & bB == 0 & bC == 0 , "a1" ,
    bA == 0 & bB == 1 & bC == 0 , "a2" ,
    bA == 1 & bB == 1 & bC == 0 , "a4" ,
    bA == 0 & bB == 1 & bC == 1 , "a5" ,
    bA == 1 & bB == 1 & bC == 1 , "a7" ,
    bA == 0 & bB == 0 & bC == 0 , "a8"
  )
]

# person-year: alert-state intensity via 2^3 = 8 possible outcomes (a1-a8) where two (a3 and a6) were not observed empirically
orc <- dt1c[,
  .(
    a1 = sum((combo == "a1") * np, na.rm = TRUE),
    a2 = sum((combo == "a2") * np, na.rm = TRUE),
    a4 = sum((combo == "a4") * np, na.rm = TRUE),
    a5 = sum((combo == "a5") * np, na.rm = TRUE),
    a7 = sum((combo == "a7") * np, na.rm = TRUE),
    a8 = sum((combo == "a8") * np, na.rm = TRUE),
    np = sum(np),
    rg = uniqueN(c(regA, regB)),
    rc = paste(sort(unique(c(regA, regB))), collapse = " + "),
    yr = first(year),
    sg = first(sex),
    ag = first(age_n)
  ),
  by = id
]

keyz <- c("a1", "a2", "a4", "a5", "a7", "a8")
orc[, ac := rowSums(.SD > 0), .SDcols = keyz]

# 6. VOLATILITY (v_moves): placement transfers/shifts within the person-year sequence for vm
moves <- dt1c[
  order(id),
  .(
    vm = sum((regA != regB) | (regA != shift(regA) & !is.na(shift(regA))))
  ),
  by = id
]

orc <- merge(orc, moves, by = "id")

setcolorder(
  orc,
  c(
    "yr",
    "ag",
    "sg",
    "np",
    "ac",
    "rg",
    "vm",
    "a1",
    "a2",
    "a4",
    "a5",
    "a7",
    "a8",
    "id",
    "rc"
  )
)

print(orc[ac > 3][order(-ac)][1:10])
print(paste("Zero day rows:", nrow(orc[np == 0])))

orc[, id := .I]
orc[, sg := ifelse(sg == "Male", 1, 2)]


# Xbar and SD for complexity and volatility by year and gender
statz <- orc[,
  .(
    n = .N,
    xA = round(mean(ac, na.rm = TRUE), 2),
    sA = round(sd(ac, na.rm = TRUE), 2),
    xB = round(mean(vm, na.rm = TRUE), 2),
    sB = round(sd(vm, na.rm = TRUE), 2)
  ),
  by = .(yr, sg)
]

statz <- statz[order(yr, sg)]
print("--- Summary Statistics for Methods Section ---")
print(statz)

orc[,
  agc := fcase(
    ag == 21 , "21" , ag == 42 , "42" , ag == 57.5 , "57.5"
  )
]

library(data.table)
library(lme4)
library(glmmTMB)
library(DHARMa)
library(cobalt)
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(Hmisc) # weighted variance/sd
# weighted mean: sum(value * weight) / sum(weight)
# weighted sd: sq rt of weighted variance

statz1a <- orc[,
  .(
    n = .N,
    xA = round(wtd.mean(ac, weights = np), 2),
    sA = round(sqrt(wtd.var(ac, weights = np)), 2),
    xB = round(wtd.mean(vm, weights = np), 2),
    sB = round(sqrt(wtd.var(vm, weights = np)), 2)
  ),
  by = .(yr, sg, agc, rc)
]
statz1a[is.na(sA), sA := mean(sB)]
statz1a[is.na(sB), sB := mean(sB)]

print(statz1a[order(yr, agc, sg, n, xA, xB, sA, sB, rc)])
# year, age, gender, region
statz1a <- statz1a[order(yr, agc, sg, n, xA, xB, sA, sB, rc)]
print("--- Detailed Summary Statistics (By Year, Demographics, and Region) ---")
print(head(statz1a, 30))
# paths by volume per year
rpvy <- statz1a[, .SD[head(order(-n), 15)], by = yr]
print(rpvy)

orc[, agc := NULL]

orc[,
  ag := fcase(
    ag == 21   , "21"   ,
    ag == 42   , "42"   ,
    ag == 57.5 , "57.5"
  )
]

orc[, rc := as.factor(rc)]
orc[, ag := factor(ag, levels = c("21", "42", "57.5"), ordered = TRUE)]
orc[, sg := factor(sg, levels = c(1, 2), labels = c("M", "F"))]
orc[, yr := factor(yr, levels = sort(unique(yr)), ordered = TRUE)]
# data types
str(orc[, .(yr, ag, sg, rc)])
orc[, treat := as.integer(ac >= 2)]
m.out <- matchit(
  treat ~ ag + sg + yr,
  data = orc,
  method = "nearest",
  distance = "glm",
  weights = orc$np
)

orc_matched <- match.data(m.out)

# fit of weighted poisson GLMM  'weights' (matching weights) via MatchIt
model_final <- glmer(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = orc_matched,
  family = poisson(link = "log"),
  weights = weights
)
# poisson model fit (matched sample)
model_final <- glmer(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = orc_matched,
  family = poisson(link = "log"),
  weights = weights
)
summary(model_final)
#  effect sizes (Incidence Rate Ratio) from log-odds
results_table <- exp(fixef(model_final))
print(results_table)

library(DHARMa)
sim_res <- simulateResiduals(model_final)
plot(sim_res)
testDispersion(sim_res)
testZeroInflation(sim_res)
library(glmmTMB)
model_final_thesis <- glmmTMB(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = orc_matched,
  family = nbinom2,
  weights = weights,
  control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS"))
)

summary(model_final_thesis)

fix_eff <- summary(model_final_thesis)$coefficients$cond

results_final <- data.frame(
  Variable = rownames(fix_eff),
  IRR = exp(fix_eff[, "Estimate"]),
  Lower_CI = exp(fix_eff[, "Estimate"] - 1.96 * fix_eff[, "Std. Error"]),
  Upper_CI = exp(fix_eff[, "Estimate"] + 1.96 * fix_eff[, "Std. Error"]),
  P_Value = fix_eff[, "Pr(>|z|)"]
)

print(results_final)
sim_res1b <- simulateResiduals(model_final_thesis, n = 5000)
plot(sim_res1b)
testDispersion(sim_res1b)
testZeroInflation(sim_res1b)
# naive weighted mean comparison to double-check the 33% increase; close to the IRR ?:!
library(weights)
wtd.mean(
  orc_matched$vm[orc_matched$treat == 1],
  weights = orc_matched$weights[orc_matched$treat == 1]
)
wtd.mean(
  orc_matched$vm[orc_matched$treat == 0],
  weights = orc_matched$weights[orc_matched$treat == 0]
)
plot(sim_res1b)
testDispersion(sim_res1b)
testZeroInflation(sim_res1b)

library(cobalt)

love_plot <- love.plot(
  m.out,
  binary = "std",
  thresholds = c(m = .1),
  var.order = "unadjusted",
  abs = TRUE,
  colors = c("red", "blue"),
  shapes = c("circle", "triangle"),
  sample.names = c("Original", "Matched"),
  stars = "std"
)

print(love_plot)

bal_table <- bal.tab(m.out, un = TRUE)
print(bal_table)
love.plot(
  m.out,
  binary = "std",
  stats = "m",
  thresholds = c(m = .1),
  abs = TRUE,
  line = TRUE,
  sample.names = c("Original (Pre-Match)", "Matched (Final Sample)"),
  colors = c("#d62728", "#1f77b4"),
  shapes = c(21, 24),
  title = "Covariate Balance Across Groups",
  xlab = "Absolute Standardized Mean Differences",
)

dml_data <- as.data.frame(orc_matched)
dml_data$sg <- as.numeric(dml_data$sg)
dml_data$ag <- as.numeric(dml_data$ag)
dml_data$yr <- as.numeric(dml_data$yr)

data_dml_obj = double_ml_data_from_data_frame(
  dml_data,
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg", "yr")
)

l_ranger = lrn("regr.ranger", num.trees = 500, max.depth = 5)

dml_model = DoubleMLPLR$new(
  data_dml_obj,
  ml_l = l_ranger,
  ml_m = l_ranger,
  n_folds = 3
) #  l = target y learner ; m = treatment d learner

dml_model$fit()
print(dml_model$summary())

dml_matrix_data <- model.matrix(
  ~ vm + treat + ag + sg + yr + rc - 1,
  data = orc_matched
)
dml_df <- as.data.frame(dml_matrix_data)
colnames(dml_df) <- make.names(colnames(dml_df))

data_dml_adj = double_ml_data_from_data_frame(
  dml_df,
  y_col = "vm",
  d_cols = "treat",
  x_cols = setdiff(colnames(dml_df), c("vm", "treat"))
)

l_ranger = lrn("regr.ranger", num.trees = 500, max.depth = 5)

dml_model_adj = DoubleMLPLR$new(
  data_dml_adj,
  ml_l = l_ranger,
  ml_m = l_ranger,
  n_folds = 3
)

dml_model_adj$fit(store_predictions = TRUE)

dml_preds_final <- dml_model_adj$predictions$ml_l[, 1, 1]

print(paste("DML Predictions Count:", length(dml_preds_final)))

glmm_preds_final <- predict(model_final_thesis, type = "response")

plot_data <- data.frame(
  Actual = as.numeric(orc_matched$vm),
  GLMM = as.numeric(glmm_preds_final),
  DML = as.numeric(dml_preds_final)
)

ggplot(plot_data) +
  geom_density(aes(x = GLMM, fill = "GLMM (Parametric)"), alpha = 0.4) +
  geom_density(aes(x = DML, fill = "DML (Machine Learning)"), alpha = 0.4) +
  scale_x_log10(labels = scales::comma) +
  labs(
    title = "Comparison of Predicted Values (Log Scale)",
    subtitle = "Revealing the distribution of low-probability GLMM predictions",
    x = "Predicted Moves (Log10 Scale)",
    y = "Density",
    fill = "Model Type"
  ) +
  theme_minimal() # log10 transformation for distribution of very small GLMM values
mse_glmm <- mean((plot_data$Actual - plot_data$GLMM)^2)
mse_dml <- mean((plot_data$Actual - plot_data$DML)^2)

cat("\n--- Initial Results ---\n")
print(dml_model_adj$summary())
cat("GLMM MSE:", round(mse_glmm, 6), "\n")
cat("DML MSE: ", round(mse_dml, 6), "\n")

summary(orc_matched$weights)
cat("Matching weight distribution:\n")
print(table(orc_matched$weights))
cat("\nBy treatment group:\n")
print(aggregate(weights ~ treat, data = orc_matched, FUN = summary))
cat("\nSample sizes by treatment:\n")
print(table(orc_matched$treat))
dml_data_clustered <- DoubleMLClusterData$new(
  data = as.data.frame(orc_matched),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg", "yr", "rc"),
  cluster_cols = "id"
)

set.seed(42569872)
dml_clustered <- DoubleMLPLR$new(
  dml_data_clustered,
  ml_l = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  ml_m = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  n_folds = 3
)

dml_clustered$fit()
print(dml_clustered$summary())

library(sandwich)
library(lmtest)
dml_data_region_clustered <- DoubleMLClusterData$new(
  data = as.data.frame(orc_matched),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg"),
  cluster_cols = c("rc", "yr")
)

set.seed(2764389)
dml_region_clustered <- DoubleMLPLR$new(
  dml_data_region_clustered,
  ml_l = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  ml_m = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  n_folds = 3
)

dml_region_clustered$fit()
print(dml_region_clustered$summary())

dml_data_region <- DoubleMLClusterData$new(
  data = as.data.frame(orc_matched),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg", "yr"),
  cluster_cols = "rc"
)

set.seed(6450835)
dml_region <- DoubleMLPLR$new(
  dml_data_region,
  ml_l = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  ml_m = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  n_folds = 3
)

dml_region$fit()
print(dml_region$summary())

dml_data_yr <- DoubleMLClusterData$new(
  data = as.data.frame(orc_matched),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg", "rc"),
  cluster_cols = "yr"
)

set.seed(69543)
dml_yearz <- DoubleMLPLR$new(
  dml_data_yr,
  ml_l = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  ml_m = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  n_folds = 3
)

dml_yearz$fit()
print(dml_yearz$summary())


dml_data_yrID <- DoubleMLClusterData$new(
  data = as.data.frame(orc_matched),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg", "rc", "id"),
  cluster_cols = "yr"
)

set.seed(2468176)
dml_yearzID <- DoubleMLPLR$new(
  dml_data_yrID,
  ml_l = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  ml_m = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  n_folds = 3
)

dml_yearzID$fit()
print(dml_yearzID$summary())

dml_data_IDz <- DoubleMLClusterData$new(
  data = as.data.frame(orc_matched),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c(
    "ag",
    "sg",
    "rc",
    "yr",
    "subclass",
    "id",
    "a1",
    "a2",
    "a4",
    "a5",
    "a7",
    "a8"
  ),
  cluster_cols = "distance"
)

set.seed(4568937)
dml_IDz <- DoubleMLPLR$new(
  dml_data_IDz,
  ml_l = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  ml_m = lrn("regr.ranger", num.trees = 500, max.depth = 5),
  n_folds = 3
)

dml_IDz$fit()
print(dml_IDz$summary())
ml_g <- lrn("regr.ranger", num.trees = 500, max.depth = 5)
ml_m <- lrn("classif.ranger", num.trees = 500, max.depth = 5)
x_cols_all <- c("ag", "sg", "rc", "yr", "a1", "a2", "a4", "a5", "a7", "a8")
orc_matched[,
  (c("sg", "rc", "yr")) := lapply(.SD, as.factor),
  .SDcols = c("sg", "rc", "yr")
]

run_dml_analysis <- function(data, x_cols, tag, cluster_var) {
  dml_data <- DoubleMLClusterData$new(
    data = as.data.frame(data),
    y_col = "vm",
    d_cols = "treat",
    x_cols = x_cols,
    cluster_cols = cluster_var
  )

  set.seed(117504871)
  obj_ate <- DoubleMLIRM$new(
    dml_data,
    ml_g = ml_g,
    ml_m = ml_m,
    n_folds = 3,
    score = "ATE"
  )
  obj_ate$fit()
  set.seed(16254911)
  obj_atte <- DoubleMLIRM$new(
    dml_data,
    ml_g = ml_g,
    ml_m = ml_m,
    n_folds = 3,
    score = "ATTE"
  )
  obj_atte$fit()

  extract <- function(obj, est) {
    ci <- obj$confint(level = 0.95)
    data.table(
      method = paste0("Clustered by ", cluster_var),
      group = tag,
      estimand = est,
      effect = as.numeric(obj$coef),
      se = as.numeric(obj$se),
      p_value = as.numeric(obj$pval),
      ci_low = as.numeric(ci[1, 1]),
      ci_high = as.numeric(ci[1, 2])
    )
  }
  return(rbind(extract(obj_ate, "ATE"), extract(obj_atte, "ATTE")))
}

res_pool_ID <- run_dml_analysis(orc_matched, x_cols_all, "Pooled", "id")

years <- sort(unique(orc_matched$yr))
x_cols_yearly <- setdiff(x_cols_all, "yr")

res_year_ID <- rbindlist(lapply(years, function(yy) {
  run_dml_analysis(orc_matched[yr == yy], x_cols_yearly, as.character(yy), "id")
}))
res_pool_SUB <- run_dml_analysis(orc_matched, x_cols_all, "Pooled", "subclass")

res_year_SUB <- rbindlist(lapply(years, function(yy) {
  run_dml_analysis(
    orc_matched[yr == yy],
    x_cols_yearly,
    as.character(yy),
    "subclass"
  )
}))

final_comparison_pool <- rbind(res_pool_ID, res_pool_SUB)
final_comparison_year <- rbind(res_year_ID, res_year_SUB)

knitr::kable(
  final_comparison_pool,
  digits = 4,
  caption = "Pooled: ID vs Subclass Clustering"
)
knitr::kable(
  final_comparison_year,
  digits = 4,
  caption = "Yearly: ID vs Subclass Clustering"
)

library(DHARMa)

run_dml_extended <- function(data, x_cols, tag, cluster_var) {
  dml_data <- DoubleMLClusterData$new(
    data = as.data.frame(data),
    y_col = "vm",
    d_cols = "treat",
    x_cols = x_cols,
    cluster_cols = cluster_var
  )

  set.seed(68235576)
  obj_ate <- DoubleMLIRM$new(dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = 3)
  obj_ate$fit(store_predictions = TRUE)
  preds_g0 <- obj_ate$predictions$ml_g0[, 1, 1]
  preds_g1 <- obj_ate$predictions$ml_g1[, 1, 1]
  dml_fitted <- ifelse(data$treat == 1, preds_g1, preds_g0)
  current_mse <- mean((data$vm - dml_fitted)^2)

  set.seed(65196489)
  sim_response <- replicate(250, rpois(length(dml_fitted), dml_fitted))
  dharma_res <- createDHARMa(
    simulatedResponse = sim_response,
    observedResponse = data$vm,
    fittedPredictedResponse = dml_fitted,
    integerResponse = TRUE
  )
  ci <- obj_ate$confint(level = 0.95)
  res_table <- data.table(
    method = paste0("Clustered by ", cluster_var),
    group = tag,
    effect = as.numeric(obj_ate$coef),
    se = as.numeric(obj_ate$se),
    p_value = as.numeric(obj_ate$pval),
    mse = current_mse,
    ci_low = as.numeric(ci[1, 1]),
    ci_high = as.numeric(ci[1, 2])
  )

  return(list(table = res_table, dharma = dharma_res, fitted = dml_fitted))
}

ml_g <- lrn("regr.ranger", num.trees = 500, max.depth = 5)
ml_m <- lrn("classif.ranger", num.trees = 500, max.depth = 5)

pooled_analysis_SUB <- run_dml_extended(
  orc_matched,
  x_cols_all,
  "Pooled",
  "subclass"
)

cat("\n--- DML Model Summary (Clustered by Subclass) ---\n")
print(pooled_analysis_SUB$table)

cat("\n--- DHARMa Diagnostics ---\n")
plot(pooled_analysis_SUB$dharma)
testOutliers(pooled_analysis_SUB$dharma, type = "bootstrap")
testDispersion(pooled_analysis_SUB$dharma)
testZeroInflation(pooled_analysis_SUB$dharma)

cat("\n--- Model Performance Comparison ---\n")
cat("GLMM MSE:", round(mse_glmm, 6), "\n")
cat("DML MSE: ", round(pooled_analysis_SUB$table$mse, 6), "\n")


ml_g <- lrn("regr.ranger", num.trees = 500, max.depth = 5)
ml_m <- lrn("classif.ranger", num.trees = 500, max.depth = 5)
x_cols_all <- c("ag", "sg", "rc", "yr", "a1", "a2", "a4", "a5", "a7", "a8")
x_cols_with_dist <- c(x_cols_all, "distance")
years <- sort(unique(orc_matched$yr))

run_dml_stable <- function(data, x_cols, tag, cluster_var) {
  dml_data <- DoubleMLClusterData$new(
    data = as.data.frame(data),
    y_col = "vm",
    d_cols = "treat",
    x_cols = x_cols,
    cluster_cols = cluster_var
  )

  set.seed(54893769)
  obj_ate <- DoubleMLIRM$new(
    dml_data,
    ml_g = ml_g,
    ml_m = ml_m,
    n_folds = 3,
    score = "ATE"
  )$fit(store_predictions = TRUE)
  set.seed(6549875)
  obj_atte <- DoubleMLIRM$new(
    dml_data,
    ml_g = ml_g,
    ml_m = ml_m,
    n_folds = 3,
    score = "ATTE"
  )$fit(store_predictions = TRUE)

  # mse
  preds_g0 <- obj_ate$predictions$ml_g0[, 1, 1]
  preds_g1 <- obj_ate$predictions$ml_g1[, 1, 1]
  dml_fitted <- ifelse(data$treat == 1, preds_g1, preds_g0)
  calc_mse <- mean((data$vm - dml_fitted)^2)

  extract <- function(obj, est) {
    ci <- obj$confint(level = 0.95)
    data.table(
      method = paste0("Clustered by ", cluster_var),
      group = tag,
      estimand = est,
      effect = as.numeric(obj$coef),
      se = as.numeric(obj$se),
      p_value = as.numeric(obj$pval),
      mse = calc_mse,
      ci_low = as.numeric(ci[1, 1]),
      ci_high = as.numeric(ci[1, 2])
    )
  }
  return(rbind(extract(obj_ate, "ATE"), extract(obj_atte, "ATTE")))
}

all_results_list <- list()

for (yy in years) {
  x_yearly <- setdiff(x_cols_all, "yr")
  all_results_list[[paste0("ID_", yy)]] <- run_dml_stable(
    orc_matched[yr == yy],
    x_yearly,
    as.character(yy),
    "id"
  )
  all_results_list[[paste0("SUB_", yy)]] <- run_dml_stable(
    orc_matched[yr == yy],
    x_yearly,
    as.character(yy),
    "subclass"
  )
}

all_results_list[["Pool_23_25_ID"]] <- run_dml_stable(
  orc_matched,
  x_cols_all,
  "Pool (23-25)",
  "id"
)
all_results_list[["Pool_23_25_SUB"]] <- run_dml_stable(
  orc_matched,
  x_cols_all,
  "Pool (23-25)",
  "subclass"
)
all_results_list[["Pool_23_24_SUB"]] <- run_dml_stable(
  orc_matched[yr %in% c("2023", "2024")],
  x_cols_all,
  "Pool (23-24)",
  "subclass"
)
all_results_list[["Pool_24_25_SUB"]] <- run_dml_stable(
  orc_matched[yr %in% c("2024", "2025")],
  x_cols_all,
  "Pool (24-25)",
  "subclass"
)

all_results_list[["Pool_Dist_Adj"]] <- run_dml_stable(
  orc_matched,
  x_cols_with_dist,
  "Pool (Dist-Adj)",
  "subclass"
)

m_results <- rbindlist(all_results_list, fill = TRUE)

m_results[, t_stat := abs(effect / se)]
m_results[, df := 1000] # DF for SEs
m_results[, RV := round(t_stat / sqrt(df), 4)]
m_results[,
  sig := cut(
    p_value,
    breaks = c(-Inf, 0.01, 0.05, 0.1, Inf),
    label = c("***", "**", "*", "")
  )
]

knitr::kable(
  m_results[
    order(group, method),
    .(group, method, estimand, effect, se, sig, RV, mse)
  ],
  digits = 4,
  caption = "Final Consolidated DML Results"
)

plot_data1b <- copy(m_results)
plot_data1b[,
  group := factor(
    group,
    levels = rev(c(
      as.character(years),
      "Pool (23-24)",
      "Pool (24-25)",
      "Pool (23-25)",
      "Pool (Dist-Adj)"
    ))
  )
]

ggplot(plot_data1b, aes(x = effect, y = group, color = method)) +
  geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.5) +
  geom_errorbarh(
    aes(xmin = ci_low, xmax = ci_high),
    height = 0.3,
    position = position_dodge(width = 0.6)
  ) +
  geom_point(position = position_dodge(width = 0.6), size = 3) +
  facet_wrap(~estimand) +
  scale_color_brewer(palette = "Set1") +
  labs(
    title = "DMLIRM Effect Stability",
    x = "Average Policy Effects of Treatment Variable",
    y = " Computational Model"
  ) +
  theme_minimal()
set.seed(5469257)
m.out1a <- matchit(
  treat ~ ag + sg + yr,
  data = orc,
  method = "nearest",
  distance = "glm",
)

orc_matched1b <- match.data(m.out1a)

love_plot1b <- love.plot(
  m.out1a,
  binary = "std",
  thresholds = c(m = .1),
  abs = TRUE,
  stars = "std",
  line = TRUE,
  sample.names = c("Original (Pre-Match)", "Matched (Final Sample)"),
  colors = c("#d62728", "#1f77b4"),
  title = "Covariate Balance"
)
print(love_plot1b)

model_final_thesis1b <- glmmTMB(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = orc_matched1b,
  family = nbinom2,
  weights = weights,
  control = glmmTMBControl(optimizer = optim, optArgs = list(method = "BFGS"))
)
fix_eff1b <- summary(model_final_thesis1b)$coefficients$cond
results_final1b <- data.frame(
  Variable = rownames(fix_eff1b),
  IRR = exp(fix_eff1b[, "Estimate"]),
  P_Value = fix_eff1b[, "Pr(>|z|)"]
)
print(results_final1b)

# DML robustness test confirms the GLMM via non-linear RF ?:!
dml_data1b <- copy(orc_matched1b)
dml_data1b[, `:=`(
  sg = as.numeric(sg),
  ag = as.numeric(ag),
  yr = as.numeric(yr)
)]

data_dml_obj1b = double_ml_data_from_data_frame(
  as.data.frame(dml_data1b),
  y_col = "vm",
  d_cols = "treat",
  x_cols = c("ag", "sg", "yr")
)

l_ranger1b = lrn("regr.ranger", num.trees = 500, max.depth = 5) # nuisance param
dml_model1b = DoubleMLPLR$new(
  data_dml_obj1b,
  ml_l = l_ranger1b,
  ml_m = l_ranger1b,
  n_folds = 3
)
dml_model1b$fit()
print(dml_model1b$summary())

fit_raw <- glm(vm ~ treat, data = orc, family = poisson()) # baseline
ate_raw <- exp(coef(fit_raw)["treat"])
# adjusted gcomp log/poisson of outcome via treatment and covariates
fit_adj <- glm(vm ~ treat + ag + sg + yr + rc, data = orc, family = poisson())
# ATE of marginality
data_t1 <- copy(orc)[, treat := 1]
data_t0 <- copy(orc)[, treat := 0]
ate_gcomp <- mean(predict(fit_adj, data_t1, type = "response")) /
  mean(predict(fit_adj, data_t0, type = "response"))

m_near <- matchit(
  treat ~ ag + sg + yr + rc,
  data = orc,
  method = "nearest",
  distance = "glm"
) # PSM
d_near <- match.data(m_near)
# psm subclassification: 'subclass' blocks
m_sub <- matchit(
  treat ~ ag + sg + yr + rc,
  data = orc,
  method = "subclass",
  subclass = 10
)
d_sub <- match.data(m_sub)

library(WeightIt)
library(survey)

w_ipw <- weightit(
  treat ~ ag + sg + yr + rc,
  data = orc,
  method = "ps",
  estimand = "ATE"
)

fit_ipw <- glm(
  vm ~ treat,
  data = orc,
  weights = w_ipw$weights,
  family = poisson()
)

library(AIPW)
library(SuperLearner)
library(glmmTMB)
library(pscl)
results_list <- list()

results_list[["Baseline_Raw"]] <- exp(coef(glm(
  vm ~ treat,
  data = orc,
  family = poisson
))["treat"])

fit_adj <- glm(vm ~ treat + ag + sg + yr + rc, data = orc, family = poisson)
results_list[["Adjusted_GComp"]] <- exp(coef(fit_adj)["treat"])

m_near <- matchit(treat ~ ag + sg + yr + rc, data = orc, method = "nearest")
d_near <- match.data(m_near)
results_list[["PSM_Nearest"]] <- exp(fixef(glmmTMB(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = d_near,
  family = poisson
))$cond["treat"])

m_sub <- matchit(
  treat ~ ag + sg + yr + rc,
  data = orc,
  method = "subclass",
  subclass = 5
)
d_sub <- match.data(m_sub)
results_list[["PSM_Subclass"]] <- exp(fixef(glmmTMB(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = d_sub,
  family = poisson
))$cond["treat"])

w_ipw <- weightit(
  treat ~ ag + sg + yr + rc,
  data = orc,
  method = "ps",
  estimand = "ATE"
)
results_list[["IPW_Weighted"]] <- exp(coef(glm(
  vm ~ treat,
  data = orc,
  weights = w_ipw$weights,
  family = poisson
))["treat"])

# nb given overdispersion ?:!
mod_nbin <- glmmTMB(
  vm ~ treat + ag + sg + yr + (1 | rc),
  data = d_near,
  family = nbinom2
)
results_list[["NegBinomial"]] <- exp(fixef(mod_nbin)$cond["treat"])

# zinb
mod_zinb <- glmmTMB(
  vm ~ treat + ag + sg + yr + (1 | rc),
  ziformula = ~1,
  data = d_near,
  family = nbinom2
)
results_list[["ZINB_Model"]] <- exp(fixef(mod_zinb)$cond["treat"])
validation_table <- data.frame(
  Method = names(results_list),
  IRR_Estimate = unlist(results_list)
)
print(validation_table)
library(AIPW)
library(randomForest)
library(gbm3)
library(SuperLearner)
sl_libs <- c("SL.glmnet", "SL.xgboost", "SL.glm", "SL.mean")
cov <- c("ag", "sg", "yr", "rg")
aipw_obj1a <- AIPW$new(
  Y = orc_matched$vm,
  A = orc_matched$treat,
  W = subset(orc_matched, select = cov),
  Q.SL.library = sl_libs,
  g.SL.library = sl_libs,
  k_split = 10,
  verbose = TRUE
)

aipw_obj1a$fit()
aipw_obj1a$stratified_fit()
aipw_obj1a$summary()
aipw_obj1a$plot.p_score(print.ip_weights = TRUE)
aipw_obj1a$plot.ip_weights()

orcmatch_temp <- copy(orc_matched1b)
orcmatch_temp[, weights := NULL]
orcmatch_temp[, treat := NULL]
orcmatch_temp[, distance := NULL]
orcmatch_temp[, subclass := NULL]
orcmatch_temp[,
  ag := fcase(
    ag == 21   , "21"   ,
    ag == 42   , "42"   ,
    ag == 57.5 , "57.5"
  )
]
orcmatch_temp[, rc := as.factor(rc)]
orcmatch_temp[,
  ag := factor(ag, levels = c("21", "42", "57.5"), ordered = TRUE)
]
orcmatch_temp[, sg := factor(sg)]
orcmatch_temp[, yr := factor(yr, levels = sort(unique(yr)), ordered = TRUE)]
orcmatch_temp$norm_weights <- orcmatch_temp$np / mean(orcmatch_temp$np)
str(orcmatch_temp[, .(yr, norm_weights, ag, sg)])
orcmatch_temp[, treat := as.numeric(ac >= median(ac))]
modout <- matchit(
  treat ~ ag + sg + yr + rg,
  data = orcmatch_temp,
  distance = "cbps",
  estimand = "ATC",
  distance.options = list(method ="exact"),
  replace = FALSE
)
modout$model$coefficients
modout$model$var
modout$model$deviance
modout$model$J
modout$model$mle.J
modout$model$method
modout$model$terms
modout$model$formula

modsum <- summary(modout)
summary(modout)
modout1a <- matchit(
  treat ~ ag + sg + yr + rg,
  data = orcmatch_temp,
  distance = "gam",
  replace = TRUE
)
modsum1a <- summary(modout1a$model)
summary(modout1a$model)
p.score <- fitted(glm(
  treat ~ ag + sg + yr + norm_weights,
  data = orcmatch_temp,
  family = binomial
))
modout1b <- matchit(
  treat ~ ag + sg + yr + norm_weights,
  data = orcmatch_temp,
  distance = p.score
)
modsum1b <- summary(modout1b$model)
summary(modout1b$model)
y1a <- orcmatch_temp[orcmatch_temp$yr == 2023, ]
y1b <- orcmatch_temp[orcmatch_temp$yr == 2024, ]
y1c <- orcmatch_temp[orcmatch_temp$yr == 2025, ]
full_mod <- lm(vm ~ . - id, data = orcmatch_temp)
backstep <- stats::step(full_mod, direction = "backward")
frontstep <- stats::step(
  lm(vm ~ 1, data = orcmatch_temp),
  scope = formula(full_mod),
  direction = "forward"
)
bothstep <- stats::step(full_mod, direction = "both")
summary(backstep)
summary(frontstep)
summary(bothstep)
# plot(bothstep)
abs_t <- sort(
  abs(summary(bothstep)$coefficients[, "t value"]),
  decreasing = TRUE
)
print(abs_t)
par(mfrow = c(2, 2))
plot(bothstep, ask = FALSE, which = 1:4)
par(mfrow = c(1, 1))
library(sjPlot)
sjPlot::plot_model(
  bothstep,
  title = "Variables selected in Stepwise Regression Model",
  subtitle = "vm ~ ac + a4 + rc + treatment + a8"
)
plot(bothstep, which = 1, main = "Model Fit", ask = FALSE)

plot_model(
  bothstep,
  title = "Target Predictors from Stepwise Regression",
  sort.est = FALSE,
  show.values = TRUE,
  value.offset = 0.4,
  type = "std"
)
final_covariates <- formula(bothstep)
print(final_covariates)

set.seed(36825994)
fmod <- lm(treat ~ . - id - vm, data = orcmatch_temp)
bstepz <- stats::step(fmod, direction = "backward")
fstepz <- stats::step(
  lm(treat ~ 1, data = orcmatch_temp),
  scope = formula(fmod),
  direction = "forward"
)
bothstepz <- stats::step(fmod, direction = "both")
stepform <- formula(bothstepz)
print(stepform)
summary(bstepz)
summary(fstepz)
summary(bothstepz)
fca <- formula(backstep)
fcb <- formula(frontstep)
fcc <- formula(bothstep)
fcd <- formula(bstepz)
fce <- formula(fstepz)
fcg <- formula(bothstepz)
fca
fcb
fcc
fcd
fce
fcg
# plot(bothstep, which = 1:4, ask = FALSE)
abs_t <- sort(
  abs(summary(bothstepz)$coefficients[, "t value"]),
  decreasing = TRUE
)
print(abs_t)
par(mfrow = c(2, 2))
plot(bothstepz, ask = FALSE, which = 1:4)
par(mfrow = c(1, 1))
library(sjPlot)
sjPlot::plot_model(
  bothstepz,
  title = "Variables selected in Stepwise Regression Model (treatment ~ sg + ac + a1 + a4 + a7 + rc)"
)
modz <- matchit(
  treat ~ sg + ac + a1 + a4 + a7 + rc,
  data = orcmatch_temp,
  distance = "cbps",
  estimand = "ATC",
  distance.options = list(method = "exact"),
  replace = TRUE
)
summary(modz)
modz1a <- match.data(modz)

library(sjmisc)
orcm <- copy(orcmatch_temp)
orcm <- to_factor(orcm, sg, rc, treat)
morc <- lm(treat ~ sg + ac + a1 + a4 + a7 + rc, data = orcm)
sjPlot::plot_model(
  morc,
  type = "pred",
  terms = c("rc", "ac", "sg"),
  title = "Stepwise Regression Prediction of Treatment",
) +
  coord_flip() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

sjPlot::plot_model(
  morc,
  title = "Stepwise Regression Prediction of Treatment",
  type = "pred",
  terms = c("rc", "ac", "sg")
) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.x = element_text(
      angle = 45, 
      hjust = 1, 
      vjust = 1,  
      size = 9   
    )
  )  
plot(bothstep, which = 1:4, ask = FALSE)
plot(bothstepz, which = 1:4, ask = FALSE)
```
